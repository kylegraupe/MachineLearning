{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-18T00:26:37.299171Z","iopub.execute_input":"2022-05-18T00:26:37.299957Z","iopub.status.idle":"2022-05-18T00:26:37.309823Z","shell.execute_reply.started":"2022-05-18T00:26:37.299914Z","shell.execute_reply":"2022-05-18T00:26:37.309070Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# TITANIC MACHINE LEARNING FROM DISASTER - Kyle Graupe","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:37.311180Z","iopub.execute_input":"2022-05-18T00:26:37.311409Z","iopub.status.idle":"2022-05-18T00:26:37.317334Z","shell.execute_reply.started":"2022-05-18T00:26:37.311381Z","shell.execute_reply":"2022-05-18T00:26:37.316680Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# READ DATA INTO PANDAS DATAFRAME\ntrain_input = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_input = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\n# VISUALIZE TRAIN AND TEST DATAFRAMES\nprint(\"\\n================\")\nprint(\"TRAIN INFO: \")\ndisplay(train_input.info())\nprint(\"\\n================\")\nprint(\"TEST INFO: \")\ndisplay(test_input.info())\n\nprint(\"\\n================\")\nprint(\"TRAIN HEAD: train_input.head(20)\")\ndisplay(train_input.head(20))\nprint(\"\\n================\")\nprint(\"TEST HEAD: \")\ndisplay(test_input.head(20))\n\nprint(\"\\n================\")\nprint(f\"TRAIN SHAPE: {train_input.shape}\")\nprint(\"\\n================\")\nprint(f\"TEST SHAPE: {test_input.shape}\")\n\nprint(\"\\n================\")\nprint(f\"TRAIN COLUMNS: \\n {train_input.columns}\")\nprint(\"\\n================\")\nprint(f\"TEST COLUMNS: \\n{test_input.columns}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:37.318510Z","iopub.execute_input":"2022-05-18T00:26:37.318704Z","iopub.status.idle":"2022-05-18T00:26:37.398796Z","shell.execute_reply.started":"2022-05-18T00:26:37.318679Z","shell.execute_reply":"2022-05-18T00:26:37.398026Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# COPY INPUT DATA\ntrain = train_input.copy()\ntest = test_input.copy()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:37.400741Z","iopub.execute_input":"2022-05-18T00:26:37.400964Z","iopub.status.idle":"2022-05-18T00:26:37.405842Z","shell.execute_reply.started":"2022-05-18T00:26:37.400933Z","shell.execute_reply":"2022-05-18T00:26:37.404873Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# FEATURE SELECTION: DROP PASSENGER ID AND NAME\n\n# CREATE A LIST OF COLUMN NAMES TO DROP\ndrop_list = [\"PassengerId\", \"Name\"]\n\n# FOR LOOP TO DROP COLUMNS BY NAME\nfor i in drop_list:\n    train = train.drop(i, axis=1)\n    test = test.drop(i, axis=1)\n    \n# CHECK THE OUTPUT\nprint(\"\\n================\")\nprint(\"TRAIN INFO: \")\nprint(train.info())\nprint(\"\\n================\")\nprint(\"TEST INFO: \")\nprint(test.info())","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:37.407214Z","iopub.execute_input":"2022-05-18T00:26:37.407513Z","iopub.status.idle":"2022-05-18T00:26:37.437647Z","shell.execute_reply.started":"2022-05-18T00:26:37.407488Z","shell.execute_reply":"2022-05-18T00:26:37.436828Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# FEATURE ENCODING\n\n# WORK WITH ENCODING COPY\ntrain_enc = train.copy()\ntest_enc = test.copy()\n\n# CREATE ONE-HOT DATAFRAMES\nembarked_OH = pd.get_dummies(train_enc.Embarked, prefix='OH_Embarked')\nsex_OH = pd.get_dummies(train_enc.Sex, prefix='OH_Sex')\n\nembarked_test_OH = pd.get_dummies(test_enc.Embarked, prefix='OH_Embarked')\nsex_test_OH = pd.get_dummies(test_enc.Sex, prefix='OH_Sex')\n\n# CHECK THE OUTPUT\nprint(\"\\n================\")\nprint(\"ONE HOT CHECK: \")\ndisplay(embarked_OH.head(10))\ndisplay(sex_OH.head(10))\n\n# ADD ONE-HOT ENCODED COLUMNS TO \"train_enc\" DATAFRAME\ntrain_enc[\"OH_C\"] = embarked_OH[\"OH_Embarked_C\"]\ntrain_enc[\"OH_Q\"] = embarked_OH[\"OH_Embarked_Q\"]\ntrain_enc[\"OH_S\"] = embarked_OH[\"OH_Embarked_S\"]\n\ntrain_enc[\"OH_female\"] = sex_OH[\"OH_Sex_female\"]\ntrain_enc[\"OH_male\"] = sex_OH[\"OH_Sex_male\"]\n\n# ADD ONE-HOT ENCODED COLUMNS TO \"test_enc\" DATAFRAME\ntest_enc[\"OH_C\"] = embarked_test_OH[\"OH_Embarked_C\"]\ntest_enc[\"OH_Q\"] = embarked_test_OH[\"OH_Embarked_Q\"]\ntest_enc[\"OH_S\"] = embarked_test_OH[\"OH_Embarked_S\"]\n\ntest_enc[\"OH_female\"] = sex_test_OH[\"OH_Sex_female\"]\ntest_enc[\"OH_male\"] = sex_test_OH[\"OH_Sex_male\"]\n\n# DROP NON-ENCODED COLUMNS\ntrain_enc = train_enc.drop(\"Embarked\", axis=1)\ntrain_enc = train_enc.drop(\"Sex\", axis=1)\n\ntest_enc = test_enc.drop(\"Embarked\", axis=1)\ntest_enc = test_enc.drop(\"Sex\", axis=1)\n\n# CHECK THE OUTPUT\nprint(\"\\n================\")\nprint(\"COLUMN CHECK: \")\nprint(train_enc.columns)\nprint(\"\\n================\")\nprint(\"DATAFRAME CHECK: \")\ndisplay(train_enc.head(20))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:37.439198Z","iopub.execute_input":"2022-05-18T00:26:37.439665Z","iopub.status.idle":"2022-05-18T00:26:37.497564Z","shell.execute_reply.started":"2022-05-18T00:26:37.439606Z","shell.execute_reply":"2022-05-18T00:26:37.496790Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"On further iteration, implement Cabin/Fare relationship algorithm. The cabin object may give insight into the survivability based on the location of the passenger (assuming they were in their cabin). The Cabin column only has 91 non-null values, but maybe the Fare and Ticket columns can help to locate the Cabin number.\n\nFor now, Cabin and Ticket will be dropped. Later iterations, we can feature extract some information from these columns, but we will ignore them for now. ","metadata":{}},{"cell_type":"code","source":"# FEATURE EXTRACTION AND ENCODING\n\n# WORK WITH COPY\ntrain_ext = train_enc.copy()\ntest_ext = test_enc.copy()\n\n# THIS COLUMN TRACKS IF THE PASSENGER HAS SIBLINGS, A SPOUSE, A PARENT, OR A CHILD ON BOARD WITH THEM (DOES NOT ACCOUNT\n# FOR GRANDPARENTS -> SOURCE OF BIAS)\n# CREATE NEW COLUMN: 1 FOR LONE TRAVELER, 0 FOR IMMEDIATE FAMILY ON BOARD\ntrain_ext[\"No Immediate Family\"] = 0\ntest_ext[\"No Immediate Family\"] = 0\n\n# ITERATE THROUGH DATAFRAME ROWS. IF NO. OF SIBLINGS/SPOUSE AND PARENTS/CHILDREN EQUALS ZERO, THEN THEY HAVE NO IMMEDIATE\n# FAMILY ON BOARD. SET VALUES TO 1 IN THIS INSTANCE.\nfor i in range(len(train_ext)):\n    if train_ext.loc[i, \"SibSp\"] == 0 and train_ext.loc[i,\"Parch\"] == 0:\n        train_ext.loc[i, \"No Immediate Family\"] = 1\n        \nfor u in range(len(test_ext)):\n    if test_ext.loc[u, \"SibSp\"] == 0 and test_ext.loc[u,\"Parch\"] == 0:\n        test_ext.loc[u, \"No Immediate Family\"] = 1\n\n# NUMBER OF LONE TRAVELERS\nprint(\"\\n================\")\nprint(\"NO IMMEDIATE FAMILY VALUE COUNTS: \")\nprint(train_ext[\"No Immediate Family\"].value_counts())\nprint(\"1 = NO IMMEDIATE FAMILY ON BOARD, 0 = IMMEDIATE FAMILY ON BOARD\")\n\ntrain_ext[\"Lone Male\"] = 0\ntrain_ext[\"Lone Female\"] = 0\n\n# ALGORITHM TO DETERMINE IF INDIVIDUAL MALES ARE TRAVELING WITHOUT IMMEDIATE FAMILY\nfor j in range(len(train_ext)):\n    if train_ext.loc[j, \"No Immediate Family\"] == 1 and train_ext.loc[j, \"OH_male\"] == 1:\n        train_ext.loc[j, \"Lone Male\"] = 1\n\n# ALGORITHM TO DETERMINE IF INDIVIDUAL FEMALES ARE TRAVELING WITHOUT IMMEDIATE FAMILY\nfor k in range(len(train_ext)):\n    if train_ext.loc[k, \"No Immediate Family\"] == 1 and train_ext.loc[k, \"OH_female\"] == 1:\n        train_ext.loc[k, \"Lone Female\"] = 1\n\n    \ntest_ext[\"Lone Male\"] = 0\ntest_ext[\"Lone Female\"] = 0\n\n# ALGORITHM TO DETERMINE IF INDIVIDUAL MALES ARE TRAVELING WITHOUT IMMEDIATE FAMILY\nfor z in range(len(test_ext)):\n    if test_ext.loc[z, \"No Immediate Family\"] == 1 and test_ext.loc[z, \"OH_male\"] == 1:\n        test_ext.loc[z, \"Lone Male\"] = 1\n\n# ALGORITHM TO DETERMINE IF INDIVIDUAL FEMALES ARE TRAVELING WITHOUT IMMEDIATE FAMILY\nfor l in range(len(test_ext)):\n    if test_ext.loc[l, \"No Immediate Family\"] == 1 and test_ext.loc[l, \"OH_female\"] == 1:\n        test_ext.loc[l, \"Lone Female\"] = 1\n\nprint(\"\\n================\")\nprint(\"LONE MALE VALUE COUNTS: \")\nprint(train_ext[\"Lone Male\"].value_counts())\nprint(\"1 = LONE MALE, 0 = IMMEDIATE FAMILE ON BOARD\")\n\nprint(\"\\n================\")\nprint(\"LONE FEMALE VALUE COUNTS: \")\nprint(train_ext[\"Lone Female\"].value_counts())\nprint(\"1 = LONE FEMALE, 0 = IMMEDIATE FAMILE ON BOARD\")\n\n# CONVERT COLUMNS TO STRING FOR WRANGLING\ntrain_ext[\"Cabin\"] = train_ext[\"Cabin\"].astype('str')\ntest_ext[\"Cabin\"] = test_ext[\"Cabin\"].astype('str')\n\n# CREATE COLUMN FOR CABIN DECK LEVEL\ntrain_ext[\"Deck\"] = ''\ntest_ext[\"Deck\"] = ''\n\n# SET DECK LEVELS\nfor h in range(len(train_ext)):\n    if train_ext.loc[h, \"Cabin\"][0] == \"A\":\n        train_ext.loc[h, \"Deck\"] = \"A\"\n    elif train_ext.loc[h, \"Cabin\"][0] == \"B\":\n        train_ext.loc[h, \"Deck\"] = \"B\"\n    elif train_ext.loc[h, \"Cabin\"][0] == \"C\":\n        train_ext.loc[h, \"Deck\"] = \"C\"\n    elif train_ext.loc[h, \"Cabin\"][0] == \"D\":\n        train_ext.loc[h, \"Deck\"] = \"D\"\n    elif train_ext.loc[h, \"Cabin\"][0] == \"E\":\n        train_ext.loc[h, \"Deck\"] = \"E\"\n    elif train_ext.loc[h, \"Cabin\"][0] == \"F\":\n        train_ext.loc[h, \"Deck\"] = \"F\"\n    elif train_ext.loc[h, \"Cabin\"][0] == \"G\":\n        train_ext.loc[h, \"Deck\"] = \"G\"\n\n# SET DECK LEVELS\nfor f in range(len(test_ext)):\n    if test_ext.loc[f, \"Cabin\"][0] == \"A\":\n        test_ext.loc[f, \"Deck\"] = \"A\"\n    elif test_ext.loc[f, \"Cabin\"][0] == \"B\":\n        test_ext.loc[f, \"Deck\"] = \"B\"\n    elif test_ext.loc[f, \"Cabin\"][0] == \"C\":\n        test_ext.loc[f, \"Deck\"] = \"C\"\n    elif test_ext.loc[f, \"Cabin\"][0] == \"D\":\n        test_ext.loc[f, \"Deck\"] = \"D\"\n    elif test_ext.loc[f, \"Cabin\"][0] == \"E\":\n        test_ext.loc[f, \"Deck\"] = \"E\"\n    elif test_ext.loc[f, \"Cabin\"][0] == \"F\":\n        test_ext.loc[f, \"Deck\"] = \"F\"\n    elif test_ext.loc[f, \"Cabin\"][0] == \"G\":\n        test_ext.loc[f, \"Deck\"] = \"G\"\n\n# CREATE DATAFRAME FOR ONE-HOT ENCODING OF DECK LEVELS\ndeck_OH = pd.get_dummies(train_ext.Deck, prefix='OH_Deck')\ndeck_test_OH = pd.get_dummies(test_ext.Deck, prefix='OH_Deck')\n\n# CHECK THE OUTPUT\nprint(\"\\n================\")\nprint(\"ONE HOT CHECK: \")\ndisplay(deck_OH.head(10))\n\n# ADD ONE-HOT ENCODED DECK DATAFRAMES TO MASTER WORKING DATAFRAME\ntrain_ext[\"A Deck\"] = deck_OH[\"OH_Deck_A\"]\ntrain_ext[\"B Deck\"] = deck_OH[\"OH_Deck_B\"]\ntrain_ext[\"C Deck\"] = deck_OH[\"OH_Deck_C\"]\ntrain_ext[\"D Deck\"] = deck_OH[\"OH_Deck_D\"]\ntrain_ext[\"E Deck\"] = deck_OH[\"OH_Deck_E\"]\ntrain_ext[\"F Deck\"] = deck_OH[\"OH_Deck_F\"]\ntrain_ext[\"G Deck\"] = deck_OH[\"OH_Deck_G\"]\ntrain_ext[\"No Deck Indicated\"] = deck_OH[\"OH_Deck_\"]\n\n# ADD ONE-HOT ENCODED DECK DATAFRAMES TO MASTER WORKING DATAFRAME\ntest_ext[\"A Deck\"] = deck_test_OH[\"OH_Deck_A\"]\ntest_ext[\"B Deck\"] = deck_test_OH[\"OH_Deck_B\"]\ntest_ext[\"C Deck\"] = deck_test_OH[\"OH_Deck_C\"]\ntest_ext[\"D Deck\"] = deck_test_OH[\"OH_Deck_D\"]\ntest_ext[\"E Deck\"] = deck_test_OH[\"OH_Deck_E\"]\ntest_ext[\"F Deck\"] = deck_test_OH[\"OH_Deck_F\"]\ntest_ext[\"G Deck\"] = deck_test_OH[\"OH_Deck_G\"]\ntest_ext[\"No Deck Indicated\"] = deck_test_OH[\"OH_Deck_\"]\n\n# GET TICKET CLASS ONE-HOT ENCODED DATAFRAME\nclass_OH = pd.get_dummies(train_ext.Pclass, prefix='OH_Class')\nclass_test_OH = pd.get_dummies(test_ext.Pclass, prefix='OH_Class')\n\n# CHECK THE OUTPUT\nprint(\"\\n================\")\nprint(\"ONE HOT CHECK: \")\ndisplay(class_OH.head(10))\n\n# ADD ONE-HOT ENCODED TICKET CLASS DATAFRAMES TO MASTER WORKING DATAFRAME\ntrain_ext[\"First Class\"] = class_OH[\"OH_Class_1\"]\ntrain_ext[\"Second Class\"] = class_OH[\"OH_Class_2\"]\ntrain_ext[\"Third Class\"] = class_OH[\"OH_Class_3\"]\n\n# ADD ONE-HOT ENCODED TICKET CLASS DATAFRAMES TO MASTER WORKING DATAFRAME\ntest_ext[\"First Class\"] = class_test_OH[\"OH_Class_1\"]\ntest_ext[\"Second Class\"] = class_test_OH[\"OH_Class_2\"]\ntest_ext[\"Third Class\"] = class_test_OH[\"OH_Class_3\"]\n\nprint(\"\\n================\")\nprint(\"TRAIN_EXT INFO: \")\nprint(train_ext.info())\n\nprint(\"\\n================\")\nprint(\"TRAIN_EXT HEAD: \")\ndisplay(train_ext.head(10))\nprint(\"\\n================\")\nprint(\"COLUMNS: \")\nprint(train_ext.columns)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:37.498932Z","iopub.execute_input":"2022-05-18T00:26:37.499191Z","iopub.status.idle":"2022-05-18T00:26:38.336498Z","shell.execute_reply.started":"2022-05-18T00:26:37.499134Z","shell.execute_reply":"2022-05-18T00:26:38.335676Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# EXTRACT CABIN NUMBER\n\n# WORK WITH COPY\ntrain_cab = train_ext.copy()\ntest_cab = test_ext.copy()\n\n# ISOLATE CABIN NUMBERS\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('A', '')\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('B', '')\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('C', '')\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('D', '0')\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('E', '')\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('F', '')\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('G', '')\ntrain_cab[\"Cabin\"] = train_cab[\"Cabin\"].str.replace('T', '0')\n\n# ISOLATE CABIN NUMBERS\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('A', '')\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('B', '')\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('C', '')\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('D', '0')\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('E', '')\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('F', '0')\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('G', '')\ntest_cab[\"Cabin\"] = test_cab[\"Cabin\"].str.replace('T', '0')\n\n# SECOND WORKING COPY\ntrain_loc = train_cab.copy()\ntest_loc = test_cab.copy()\n\n# CREATE NEW COLUMN FOR PORT VS STARBOARD CABIN CLASSIFICATION: PORT = 1, STBD = 0\ntrain_cab[\"Cabin P/S\"] = 1\ntest_cab[\"Cabin P/S\"] = 1\n\n# TRAIN SET\n\n# HARD CODE STRING REPLACEMENT\nfor p in range(len(train_loc)):\n    if train_loc.loc[p, \"Cabin\"] == \"nan\":\n        train_loc.loc[p, \"Cabin\"] = \"0\"\n    if train_loc.loc[p, \"Cabin\"] == ' ':\n        train_loc.loc[p, \"Cabin\"] == '0'\n\n# FIND CABIN NUMBER\nfor q in range(len(train_loc)):\n    a = train_loc.loc[q, \"Cabin\"].split()\n    b = [int(x) for x in a]\n    train_loc.loc[q, \"Cabin\"] = b[0]\n\n# BINARY PORT/STARBOARD CLASSIFICATION\nfor r in range(len(train_loc)):\n    if train_loc.loc[r, \"Cabin\"] % 2 == 0:\n        train_cab.loc[r, \"Cabin P/S\"] = 0\n\n# HARD CODE STRING REPLACEMENT\nfor n in range(len(train_cab)):\n    if train_cab.loc[n, \"Cabin\"] == \"nan\":\n        train_cab.loc[n, \"Cabin\"] = \"0\"\n    if train_cab.loc[n, \"Cabin\"] == ' ':\n        train_cab.loc[n, \"Cabin\"] == '0'\n\n# FIND AVERAGE OF CABIN NUMBERS IN CASE THEY WERE BOUGHT TOGETHER\nfor o in range(len(train_cab)):\n    a = train_cab.loc[o, \"Cabin\"].split()\n    b = [int(x) for x in a]\n    num_sum = sum(b)\n    avg = num_sum/len(b)\n    train_cab.loc[o, \"Cabin\"] = avg\n    \n# TEST SET \n\n# HARD CODE STRING REPLACEMENT\nfor aa in range(len(test_loc)):\n    if test_loc.loc[aa, \"Cabin\"] == \"nan\":\n        test_loc.loc[aa, \"Cabin\"] = \"0\"\n    if test_loc.loc[aa, \"Cabin\"] == ' ':\n        test_loc.loc[aa, \"Cabin\"] == '0'\n\n\n# for q in range(len(train_loc)):\n#     a = train_loc.loc[q, \"Cabin\"].split()\n#     b = [int(x) for x in a]\n#     train_loc.loc[q, \"Cabin\"] = b[0]\n\n# FIND CABIN NUMBER OF FIRST INSTANCE (IN CASE IN LIST OF CABIN NUMBERS)\nfor bb in range(len(test_loc)):\n    a_1 = test_loc.loc[bb, \"Cabin\"].split()\n    b_1 = [int(x_1) for x_1 in a_1]\n    test_loc.loc[bb, \"Cabin\"] = b_1[0]\n\n# DETERMINE IF CABIN IS ON PORT OR STARBOARD SIDE. SHIPS HAVE EVEN NUMBER COMPARTMENTS FOR STARBOARD, ODD FOR PORT\nfor cc in range(len(test_loc)):\n    if test_loc.loc[cc, \"Cabin\"] % 2 == 0:\n        test_cab.loc[cc, \"Cabin P/S\"] = 0\n\n# HARDCODE STRING REPLACEMENT\nfor dd in range(len(test_cab)):\n    if test_cab.loc[dd, \"Cabin\"] == \"nan\":\n        test_cab.loc[dd, \"Cabin\"] = \"0\"\n    if test_cab.loc[dd, \"Cabin\"] == ' ':\n        test_cab.loc[dd, \"Cabin\"] == '0'\n\n# FIND AVERAGE LOCATION OF CABIN\nfor ee in range(len(test_cab)):\n    a_2 = test_cab.loc[ee, \"Cabin\"].split()\n    b_2 = [int(x_2) for x_2 in a_2]\n    num_sum_2 = sum(b_2)\n    avg_2 = num_sum_2/len(b_2)\n    test_cab.loc[ee, \"Cabin\"] = avg_2\n\nprint(\"\\n================\")\ndisplay(train_cab.head(10))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:38.338462Z","iopub.execute_input":"2022-05-18T00:26:38.338768Z","iopub.status.idle":"2022-05-18T00:26:39.871130Z","shell.execute_reply.started":"2022-05-18T00:26:38.338728Z","shell.execute_reply":"2022-05-18T00:26:39.870325Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# EXTRACT DATA FROM SIBLINGS/SPOUSES AND PARENTS/CHILDREN","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:39.873524Z","iopub.execute_input":"2022-05-18T00:26:39.873819Z","iopub.status.idle":"2022-05-18T00:26:39.877388Z","shell.execute_reply.started":"2022-05-18T00:26:39.873788Z","shell.execute_reply":"2022-05-18T00:26:39.876402Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# DROP IRRELEVANT COLUMNS (THOSE THAT HAVE BEEN ENCODED)\n\n# WORK WITH COPY\ntrain_drop = train_cab.copy()\ntest_drop = test_cab.copy()\n\n# CREATE LIST OF COLUMNS TO DROP\ndrop_list_2 = [\"Pclass\", \"Ticket\", \"Cabin\", \"Deck\"]\n\n# ITERATE AND DROP COLUMNS SPECIFIED ABOVE\nfor t in drop_list_2:\n    train_drop = train_drop.drop(t, axis=1)\n    test_drop = test_drop.drop(t, axis=1)\n\nprint(\"\\n================\")\nprint(\"TRAIN HEAD: \")\ndisplay(train_drop.head())\nprint(\"\\n================\")\nprint(\"TRAIN INFO: \")\nprint(train_drop.info())\nprint(\"\\n================\")\nprint(\"TEST HEAD: \")\ndisplay(test_drop.head())\nprint(\"\\n================\")\nprint(\"TEST INFO: \")\nprint(test_drop.info())","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:39.878499Z","iopub.execute_input":"2022-05-18T00:26:39.878711Z","iopub.status.idle":"2022-05-18T00:26:39.944672Z","shell.execute_reply.started":"2022-05-18T00:26:39.878687Z","shell.execute_reply":"2022-05-18T00:26:39.943831Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n# REPLACE MISSING VALUES FOR AGE\n\n# WORK WITH COPY\ntrain_imp = train_drop.copy()\ntest_imp = test_drop.copy()\n\n# CONVERT AGE COLUMN TO FLOATS\ntrain_imp[\"Age\"] = train_imp[\"Age\"].astype(float)\ntest_imp[\"Age\"] = test_imp[\"Age\"].astype(float)\n\nprint(\"\\n================\")\nprint(\"TRAIN DATATYPES: \")\nprint(train_imp.dtypes)\nprint(\"\\n================\")\nprint(\"TEST DATATYPES: \")\nprint(test_imp.dtypes)\n\n# INSTANTIATE SIMPLEIMPUTER\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\n\n# CONVERT IMPUTED DATA BACK INTO PANDAS DATAFRAME\ntrain_imp = pd.DataFrame(imputer.fit_transform(train_imp), columns=train_drop.columns, index=train_drop.index)\ntest_imp = pd.DataFrame(imputer.fit_transform(test_imp), columns=test_drop.columns, index=test_drop.index)\n\ntrain_imp[\"Minor\"] = 0\n\nfor iter in range(len(train_imp)):\n    if train_imp.loc[iter, \"Age\"] <= 12.0:\n        train_imp.loc[iter, \"Minor\"] = 1\n        \ntest_imp[\"Minor\"] = 0\n\nfor iter_minor in range(len(test_imp)):\n    if test_imp.loc[iter_minor, \"Age\"] <= 12.0:\n        test_imp.loc[iter_minor, \"Minor\"] = 1\n        \n# train_imp[\"Senior Citizen\"] = 0\n\n# for iter_1 in range(len(train_imp)):\n#     if train_imp.loc[iter_1, \"Age\"] >= 60:\n#         train_imp.loc[iter_1, \"Senior Citizen\"] = 1\n        \n# train_imp[\"Lone Minor\"] = 0\n\n# for iter_2 in range(len(train_imp)):\n#     if train_imp.loc[iter_2, \"Age\"] <= 12.0 and train_imp.loc[iter_2, \"SibSp\"] == 0 and train_imp.loc[iter_2, \"Parch\"] == 0:\n#         train_imp.loc[iter_2, \"Lone Minor\"] = 1\n        \n# train_imp[\"Lone Male Senior Citizen\"] = 0\n\n# for iter_3 in range(len(train_imp)):\n#     if train_imp.loc[iter_3, \"Age\"] >= 60 and train_imp.loc[iter_3, \"Lone Male\"] == 1:\n#         train_imp.loc[iter_3, \"Lone Male Senior Citizen\"] = 1\n        \n# train_imp[\"Lone Female Senior Citizen\"] = 0\n\n# for iter_4 in range(len(train_imp)):\n#     if train_imp.loc[iter_4, \"Age\"] >= 60 and train_imp.loc[iter_4, \"Lone Female\"] == 1:\n#         train_imp.loc[iter_4, \"Lone Female Senior Citizen\"] = 1\n        \ntrain_imp[\"First Class Woman\"] = 0\ntrain_imp[\"First Class Child\"] = 0\ntrain_imp[\"First Class Man\"] = 0\n\nfor iter_0 in range(len(train_imp)):\n    if train_imp.loc[iter_0, \"OH_female\"] == 1 and train_imp.loc[iter_0, \"Age\"] >= 12.0 and train_imp.loc[iter_0, \"First Class\"] == 1:\n        train_imp.loc[iter_0, \"First Class Woman\"] = 1\n        \nfor iter_1 in range(len(train_imp)):\n    if train_imp.loc[iter_1, \"Age\"] <= 12 and train_imp.loc[iter_1, \"First Class\"] == 1:\n        train_imp.loc[iter_1, \"First Class Child\"] = 1\n        \nfor iter_2 in range(len(train_imp)):\n    if train_imp.loc[iter_2, \"OH_male\"] == 1 and train_imp.loc[iter_2, \"Age\"] >= 12.0 and train_imp.loc[iter_2, \"First Class\"] == 1:\n        train_imp.loc[iter_2, \"First Class Man\"] = 1\n    \n# *************\n\ntest_imp[\"First Class Woman\"] = 0\ntest_imp[\"First Class Child\"] = 0\ntest_imp[\"First Class Man\"] = 0\n\nfor iter_a in range(len(test_imp)):\n    if test_imp.loc[iter_a, \"OH_female\"] == 1 and test_imp.loc[iter_a, \"Age\"] >= 12.0 and test_imp.loc[iter_a, \"First Class\"] == 1:\n        test_imp.loc[iter_a, \"First Class Woman\"] = 1\n        \nfor iter_b in range(len(test_imp)):\n    if test_imp.loc[iter_b, \"Age\"] <= 12 and test_imp.loc[iter_b, \"First Class\"] == 1:\n        test_imp.loc[iter_b, \"First Class Child\"] = 1\n        \nfor iter_c in range(len(test_imp)):\n    if test_imp.loc[iter_c, \"OH_male\"] == 1 and test_imp.loc[iter_c, \"Age\"] >= 12.0 and test_imp.loc[iter_c, \"First Class\"] == 1:\n        test_imp.loc[iter_c, \"First Class Man\"] = 1\n\n# **********\n\ntrain_imp[\"Second Class Woman\"] = 0\ntrain_imp[\"Second Class Child\"] = 0\ntrain_imp[\"Second Class Man\"] = 0\n\nfor iter_3 in range(len(train_imp)):\n    if train_imp.loc[iter_3, \"OH_female\"] == 1 and train_imp.loc[iter_3, \"Age\"] >= 12.0 and train_imp.loc[iter_3, \"Second Class\"] == 1:\n        train_imp.loc[iter_3, \"Second Class Woman\"] = 1\n\nfor iter_4 in range(len(train_imp)):\n    if train_imp.loc[iter_4, \"Age\"] <= 12.0 and train_imp.loc[iter_4, \"Second Class\"] == 1:\n        train_imp.loc[iter_4, \"Second Class Child\"] = 1\n\nfor iter_5 in range(len(train_imp)):\n    if train_imp.loc[iter_5, \"OH_male\"] == 1 and train_imp.loc[iter_5, \"Age\"] >= 12.0 and train_imp.loc[iter_5, \"Second Class\"] == 1:\n        train_imp.loc[iter_5, \"Second Class Man\"] = 1\n        \n# *************\n\ntest_imp[\"Second Class Woman\"] = 0\ntest_imp[\"Second Class Child\"] = 0\ntest_imp[\"Second Class Man\"] = 0\n\nfor iter_d in range(len(test_imp)):\n    if test_imp.loc[iter_d, \"OH_female\"] == 1 and test_imp.loc[iter_d, \"Age\"] >= 12.0 and test_imp.loc[iter_d, \"Second Class\"] == 1:\n        test_imp.loc[iter_d, \"Second Class Woman\"] = 1\n        \nfor iter_e in range(len(test_imp)):\n    if test_imp.loc[iter_e, \"Age\"] <= 12 and test_imp.loc[iter_e, \"Second Class\"] == 1:\n        test_imp.loc[iter_e, \"Second Class Child\"] = 1\n        \nfor iter_f in range(len(test_imp)):\n    if test_imp.loc[iter_f, \"OH_male\"] == 1 and test_imp.loc[iter_f, \"Age\"] >= 12.0 and test_imp.loc[iter_f, \"Second Class\"] == 1:\n        test_imp.loc[iter_f, \"Second Class Man\"] = 1\n        \n# *************\n        \ntrain_imp[\"Third Class Woman\"] = 0\ntrain_imp[\"Third Class Child\"] = 0\ntrain_imp[\"Third Class Man\"] = 0\n\nfor iter_6 in range(len(train_imp)):\n    if train_imp.loc[iter_6, \"OH_female\"] == 1 and train_imp.loc[iter_6, \"Age\"] >= 12.0 and train_imp.loc[iter_6, \"Third Class\"] == 1:\n        train_imp.loc[iter_6, \"Third Class Woman\"] = 1\n        \nfor iter_7 in range(len(train_imp)):\n    if train_imp.loc[iter_7, \"Age\"] <= 12.0 and train_imp.loc[iter_7, \"Third Class\"] == 1:\n        train_imp.loc[iter_7, \"Third Class Child\"] = 1\n        \nfor iter_8 in range(len(train_imp)):\n    if train_imp.loc[iter_8, \"OH_male\"] == 1 and train_imp.loc[iter_8, \"Age\"] >= 12.0 and train_imp.loc[iter_8, \"Third Class\"] == 1:\n        train_imp.loc[iter_8, \"Third Class Man\"] = 1\n\n# **************\n\ntest_imp[\"Third Class Woman\"] = 0\ntest_imp[\"Third Class Child\"] = 0\ntest_imp[\"Third Class Man\"] = 0\n\nfor iter_g in range(len(test_imp)):\n    if test_imp.loc[iter_g, \"OH_female\"] == 1 and test_imp.loc[iter_g, \"Age\"] >= 12.0 and test_imp.loc[iter_g, \"Third Class\"] == 1:\n        test_imp.loc[iter_g, \"Third Class Woman\"] = 1\n        \nfor iter_h in range(len(test_imp)):\n    if test_imp.loc[iter_h, \"Age\"] <= 12 and test_imp.loc[iter_h, \"Third Class\"] == 1:\n        test_imp.loc[iter_h, \"Third Class Child\"] = 1\n        \nfor iter_i in range(len(test_imp)):\n    if test_imp.loc[iter_i, \"OH_male\"] == 1 and test_imp.loc[iter_i, \"Age\"] >= 12.0 and test_imp.loc[iter_i, \"Third Class\"] == 1:\n        test_imp.loc[iter_i, \"Third Class Man\"] = 1\n\nprint(\"\\n================\")\nprint(\"SECOND CLASS CHILD COUNTS: \")\nprint(train_imp[\"Second Class Child\"].value_counts())\n\nprint(\"\\n================\")\nprint(\"TRAIN HEAD: \")\ndisplay(train_imp.head(10))\nprint(\"\\n================\")\nprint(\"TRAIN INFO: \")\nprint(train_imp.info())\n\nprint(\"\\n================\")\nprint(\"TEST HEAD: \")\ndisplay(test_imp.head(10))\nprint(\"\\n================\")\nprint(\"TEST INFO: \")\nprint(test_imp.info())","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:39.946022Z","iopub.execute_input":"2022-05-18T00:26:39.946582Z","iopub.status.idle":"2022-05-18T00:26:40.823362Z","shell.execute_reply.started":"2022-05-18T00:26:39.946552Z","shell.execute_reply":"2022-05-18T00:26:40.822809Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# SCALE NON-BINARY DATA\n\n# WORK WITH COPY\ntrain_sca = train_imp.copy()\ntest_sca = test_imp.copy()\n\n# INSTANTIATE SCALER\nscaler = MinMaxScaler()\n\ntrain_sca[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]] = scaler.fit_transform(train_sca[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]])\ntest_sca[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]] = scaler.fit_transform(test_sca[[\"Age\", \"SibSp\", \"Parch\", \"Fare\"]])\n\nprint(\"\\n================\")\nprint(\"TRAIN HEAD: \")\ndisplay(train_sca.head(10))\n\nprint(\"\\n================\")\nprint(\"TEST HEAD: \")\ndisplay(test_sca.head(10))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:40.824185Z","iopub.execute_input":"2022-05-18T00:26:40.824368Z","iopub.status.idle":"2022-05-18T00:26:40.891791Z","shell.execute_reply.started":"2022-05-18T00:26:40.824344Z","shell.execute_reply":"2022-05-18T00:26:40.890958Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"correlation_sorted = train_sca.corr()\ncorrelation_grouped = train_sca.corr()[\"Survived\"][:]\nprint(\"\\n================\")\nprint(\"GROUPED CORRELATION: \")\nprint(correlation_grouped)\nprint(\"\\n================\")\nprint(\"SORTED CORRELATION: \")\nprint(correlation_sorted[\"Survived\"].sort_values(ascending=False))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:40.893248Z","iopub.execute_input":"2022-05-18T00:26:40.893606Z","iopub.status.idle":"2022-05-18T00:26:40.913516Z","shell.execute_reply.started":"2022-05-18T00:26:40.893556Z","shell.execute_reply":"2022-05-18T00:26:40.912693Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# FEATURE DROPPING","metadata":{}},{"cell_type":"code","source":"train_fe = train_sca.copy()\ntest_fe = test_sca.copy()\n\n# DROP UNCORRELATED COLUMNS\nfinal_drop_list = [\"Parch\", \"SibSp\", \"Age\", \"First Class\", \"Second Class\", \"Third Class\", \"OH_female\", \"OH_male\", \n                  \"A Deck\", \"B Deck\", \"C Deck\", \"D Deck\", \"E Deck\", \"F Deck\", \"G Deck\"]\n\nfor drop_iter in final_drop_list:\n    train_fe = train_fe.drop(drop_iter, axis=1)\n    test_fe = test_fe.drop(drop_iter, axis=1)\n\nprint(\"\\n================\")\nprint(f\"FINAL TRAIN COLUMNS: \\n{train_fe.columns}\")\nprint(\"\\n================\")\nprint(f\"FINAL TEST COLUMNS: \\n{test_fe.columns}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:40.914635Z","iopub.execute_input":"2022-05-18T00:26:40.914848Z","iopub.status.idle":"2022-05-18T00:26:40.942471Z","shell.execute_reply.started":"2022-05-18T00:26:40.914821Z","shell.execute_reply":"2022-05-18T00:26:40.941648Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.models\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import svm\nfrom sklearn.utils import shuffle\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:40.943655Z","iopub.execute_input":"2022-05-18T00:26:40.944325Z","iopub.status.idle":"2022-05-18T00:26:47.083223Z","shell.execute_reply.started":"2022-05-18T00:26:40.944289Z","shell.execute_reply":"2022-05-18T00:26:47.082410Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"SPLIT TRAIN, DEV, TEST, BEFORE DATA PREP","metadata":{}},{"cell_type":"code","source":"# SPLIT TRAIN, DEV, TEST SETS\ntrain_fin = train_fe.copy()\ntest_fin = test_fe.copy()\ntrain_fin.to_csv(\"train_csv_final.csv\", index=False)\ntest_fin.to_csv(\"test_csv_final.csv\", index=False)\nfeatures_0 = train_fin.loc[:, \"Fare\": \"Third Class Man\"]\nlabels_0 = train_fin.loc[:, : \"Survived\"].astype(int)\n\nfeatures, labels = shuffle(features_0, labels_0)\n\n# print(features)\n# print(labels)\n\nx_train, x_rem, y_train, y_rem = train_test_split(features, labels, train_size=0.8)\n\ntest_size = 0.5\n\nx_dev, x_test, y_dev, y_test = train_test_split(x_rem,y_rem, test_size=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:47.084295Z","iopub.execute_input":"2022-05-18T00:26:47.085522Z","iopub.status.idle":"2022-05-18T00:26:47.122219Z","shell.execute_reply.started":"2022-05-18T00:26:47.085487Z","shell.execute_reply":"2022-05-18T00:26:47.121309Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)\n{'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:47.123630Z","iopub.execute_input":"2022-05-18T00:26:47.123977Z","iopub.status.idle":"2022-05-18T00:26:47.144123Z","shell.execute_reply.started":"2022-05-18T00:26:47.123935Z","shell.execute_reply":"2022-05-18T00:26:47.142795Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import time\n\nstart = time.time()\n# # Use the random grid to search for best hyperparameters\n# # First create the base model to tune\n# rf = RandomForestClassifier()\n# # Random search of parameters, using 3 fold cross validation, \n# # search across 100 different combinations, and use all available cores\n# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# # Fit the random search model\n# rf_random.fit(x_train, y_train.values.ravel())\n\n# rf_best = rf_random.best_params_\nend = time.time()\n\nprint(\"\\n================\")\nprint(f\"Model training run time: {end-start}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:47.145873Z","iopub.execute_input":"2022-05-18T00:26:47.146376Z","iopub.status.idle":"2022-05-18T00:26:47.157588Z","shell.execute_reply.started":"2022-05-18T00:26:47.146332Z","shell.execute_reply":"2022-05-18T00:26:47.154803Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"{'n_estimators': 2000, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 30, 'bootstrap': False}","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score\n\nrf_use = RandomForestClassifier(n_estimators=2000, min_samples_split=2, min_samples_leaf=1, max_features='auto',\n                               max_depth=5, bootstrap=False)\n\nrf_use.fit(x_train, y_train.values.ravel())\n\ny_pred = rf_use.predict(x_train)\nacc_score = accuracy_score(y_train, y_pred)\nconfusion_matrix = confusion_matrix(y_train, y_pred)\nf1 = f1_score(y_train, y_pred)\nprint(\"\\n================\")\nprint(f\"ACCURACY SCORE ON TRAIN SET: \\n{acc_score}\")\nprint(\"\\n================\")\nprint(f\"CONFUSION MATRIX ON TRAIN SET: \\n{confusion_matrix}\")\nprint(\"\\n================\")\nprint(f\"F1 SCORE ON TRAIN SET: \\n{f1}\")\n\n\n\n# rf_full = cross_val_score(rf_use, features, labels.values.ravel(), cv=10)\n# rf_cv_train = cross_val_score(rf_use, x_train, y_train.values.ravel(), cv=10)\n# rf_cv_dev = cross_val_score(rf_use, x_dev, y_dev.values.ravel(), cv=10)\n# rf_cv_test = cross_val_score(rf_use, x_test, y_test.values.ravel(), cv=10)\n\n# print(\"\\n================\")\n# print(\"MEAN SCORES OF TUNED RANDOM FOREST CLASSIFIER, FULL (k = 10): \")\n# print(mean(rf_full))\n\n# print(\"\\n================\")\n# print(\"MEAN SCORES OF TUNED RANDOM FOREST CLASSIFIER, TRAIN (k = 10): \")\n# print(mean(rf_cv_train))\n\n# print(\"\\n================\")\n# print(\"MEAN SCORES OF TUNED RANDOM FOREST CLASSIFIER, DEV (k = 10): \")\n# print(mean(rf_cv_dev))\n\n# print(\"\\n================\")\n# print(\"MEAN SCORES OF TUNED RANDOM FOREST CLASSIFIER, TEST (k = 10): \")\n# print(mean(rf_cv_test))","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:47.158929Z","iopub.execute_input":"2022-05-18T00:26:47.159675Z","iopub.status.idle":"2022-05-18T00:26:50.219508Z","shell.execute_reply.started":"2022-05-18T00:26:47.159617Z","shell.execute_reply":"2022-05-18T00:26:50.218865Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"**Added features increased the training accuracy of the random forest, but also increased variance. Drop uncorrelated values and make sure to add the newly engineered features to the test set. ******","metadata":{}},{"cell_type":"code","source":"out = rf_use.predict(test_fin)\nout_df = pd.DataFrame(out, columns=[\"Survived\"], index=test_fin.index)\n\ntest_temp = test_input.copy()\nout_df[\"PassengerId\"] = test_temp[\"PassengerId\"]\n\nout_df.to_csv(\"submission prediction 15.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:50.220642Z","iopub.execute_input":"2022-05-18T00:26:50.221473Z","iopub.status.idle":"2022-05-18T00:26:50.495643Z","shell.execute_reply.started":"2022-05-18T00:26:50.221430Z","shell.execute_reply":"2022-05-18T00:26:50.495033Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import accuracy_score\n# # from sklearn.metrics import classification_matrix\n\n# nn = create_baseline()\n# nn.fit(x_train, y_train.values.ravel(), verbose=0)\n# y_pred = nn.predict(x_train)\n# # y_pred = int(y_pred)\n# # print(y_pred.dtype)\n# y_pred = pd.DataFrame(y_pred, columns=[\"Survived\"], index=x_train.index).astype(int)\n# print(y_pred.dtypes)\n\n\n\n# acc_score = accuracy_score(y_train, y_pred)\n# # class_matrix = classification_matrix(y_train, y_pred)\n\n# train_loss, train_acc = nn.evaluate(x_train, y_train)\n\n# print(train_loss)\n# print(train_acc)\n# print(acc_score)\n# # print(class_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:50.496706Z","iopub.execute_input":"2022-05-18T00:26:50.497581Z","iopub.status.idle":"2022-05-18T00:26:50.502124Z","shell.execute_reply.started":"2022-05-18T00:26:50.497537Z","shell.execute_reply":"2022-05-18T00:26:50.501353Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# train_loss, train_acc = nn.evaluate(x_train, y_train)\n# dev_loss, dev_acc = nn.evaluate(x_dev, y_dev)\n\n# print(\"\\n================\")\n# print(\"TRAIN ACC, TRAIN LOSS: [\"  + str(train_acc) + \", \" + str(train_loss) + \"]\")\n\n# print(\"\\n================\")\n# print(\"TRAIN ACC, TRAIN LOSS: [\"  + str(dev_acc) + \", \" + str(dev_loss) + \"]\")\n\nout = estimator.predict(test_fin)\nout_df = pd.DataFrame(out, columns=[\"Survived\"], index=test_fin.index)\n\ntest_temp = test_input.copy()\nout_df[\"PassengerId\"] = test_temp[\"PassengerId\"]\n\nout_df.to_csv(\"submission prediction 12.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:50.503410Z","iopub.execute_input":"2022-05-18T00:26:50.503921Z","iopub.status.idle":"2022-05-18T00:26:50.793644Z","shell.execute_reply.started":"2022-05-18T00:26:50.503882Z","shell.execute_reply":"2022-05-18T00:26:50.792516Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# rf_use.fit(features, labels.values.ravel())\n# output = rf_use.predict(test_fin)\n# output_df = pd.DataFrame(output, columns=[\"Survived\"], index=test_fin.index)\n# #\n# test_temp = test_input.copy()\n# print(test_temp.columns)\n# output_df[\"PassengerId\"] = test_temp[\"PassengerId\"]\n# print(output_df.columns)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:50.794707Z","iopub.status.idle":"2022-05-18T00:26:50.795195Z","shell.execute_reply.started":"2022-05-18T00:26:50.794947Z","shell.execute_reply":"2022-05-18T00:26:50.794973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output_df.to_csv('submission predictions 9.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T00:26:50.796122Z","iopub.status.idle":"2022-05-18T00:26:50.796427Z","shell.execute_reply.started":"2022-05-18T00:26:50.796272Z","shell.execute_reply":"2022-05-18T00:26:50.796288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}